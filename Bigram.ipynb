{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9UkDauX8Byb3"
      },
      "outputs": [],
      "source": [
        "from submit import my_fit, my_predict\n",
        "import time as tm\n",
        "import pickle\n",
        "import warnings\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open( \"/content/dict (1)\", 'r' ) as f:\n",
        "\twords = f.read().split( '\\n' )[:-1]\t\t# Omit the last line since it is empty\n",
        "\tnum_words = len( words )"
      ],
      "metadata": {
        "id": "Wdq2X6uVB8rh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_trials = 5\n",
        "\n",
        "t_train = 0\n",
        "m_size = 0\n",
        "t_test = 0\n",
        "prec = 0"
      ],
      "metadata": {
        "id": "UQrLNsaGB-f_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bigrams( word, lim = None ):\n",
        "  # Get all bigrams\n",
        "  bg = map( ''.join, list( zip( word, word[1:] ) ) )\n",
        "  # Remove duplicates and sort them\n",
        "  bg = sorted( set( bg ) )\n",
        "  # Make them into an immutable tuple and retain only the first few\n",
        "  return tuple( bg )[:lim]"
      ],
      "metadata": {
        "id": "MAsWDD5iChyt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lim_bg = 5\n",
        "lim_out = 5\n",
        "\n",
        "for t in range( n_trials ):\n",
        "    tic = tm.perf_counter()  # Use spaces for indentation consistently\n",
        "    model = my_fit( words )\n",
        "    toc = tm.perf_counter()\n",
        "    t_train += toc - tic\n",
        "\n",
        "    with open( f\"model_dump_{t}.pkl\", \"wb\" ) as outfile:\n",
        "        pickle.dump( model, outfile, protocol = pickle.HIGHEST_PROTOCOL )\n",
        "\n",
        "    m_size += os.path.getsize( f\"model_dump_{t}.pkl\" )\n",
        "\n",
        "    tic = tm.perf_counter()\n",
        "\n",
        "    for ( i, word ) in enumerate( words ):\n",
        "        bg = get_bigrams( word, lim = lim_bg )\n",
        "        guess_list = my_predict( model, bg )\n",
        "\n",
        "        # Do not send long guess lists -- they will result in lower marks\n",
        "        guess_len = len( guess_list )\n",
        "        # Ignore all but the first 5 guesses\n",
        "        guess_list = guess_list[ :lim_out ]\n",
        "\n",
        "        # Notice that if 10 guesses are made, one of which is correct,\n",
        "        # score goes up by 1/10 even though only first 5 guesses are considered\n",
        "        # Thus, it is never beneficial to send more than 5 guesses\n",
        "        if word in guess_list:\n",
        "            prec += 1 / guess_len\n",
        "\n",
        "    toc = tm.perf_counter()\n",
        "\n",
        "    t_test += toc - tic"
      ],
      "metadata": {
        "id": "nXPxzZbct_sn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_train /= n_trials\n",
        "m_size /= n_trials\n",
        "t_test /= n_trials\n",
        "prec /= ( n_trials * num_words )\n",
        "\n",
        "print( t_train, m_size, prec, t_test )"
      ],
      "metadata": {
        "id": "Vmub4R58CJ1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff1612d-64e9-4f68-a8e0-0bfff178cf6e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.035860524200006696 643705.0 0.9750338687826587 6.102689372600002\n"
          ]
        }
      ]
    }
  ]
}